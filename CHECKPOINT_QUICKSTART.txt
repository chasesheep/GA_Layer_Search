================================================================================
模型Checkpoint生成 - 快速开始
================================================================================

📋 目的: 将GA搜索发现的层组合转换为可直接使用的完整模型checkpoint

🎯 基于搜索结果 [11, 13, 17, 21]，MMLU分数 0.5700

================================================================================
前置要求
================================================================================

1. ✅ 已完成模型准备（提取Llama层文件）
   cd model_preparation/
   python extract_layers.py --model_name llama --output_dir ../extracted_llama_layers

2. ✅ 磁盘空间充足（每个checkpoint约16GB）

3. ✅ GPU可用（需要18GB+显存）

================================================================================
方式1: 创建单个Checkpoint（推荐用于测试）
================================================================================

cd model_preparation/

# 创建11, 13, 17, 21层替换的checkpoint
python create_replaced_model_checkpoint.py \
    --layers 11 13 17 21 \
    --output_dir ../model_checkpoints/llamba_replaced_11_13_17_21 \
    --description "GA搜索发现的4层最优组合" \
    --score 0.5700 \
    --gpu 0

预计时间: 5-10分钟
输出大小: ~16GB
输出位置: model_checkpoints/llamba_replaced_11_13_17_21/

================================================================================
方式2: 批量创建所有最优Checkpoint
================================================================================

cd model_preparation/

# 批量创建所有GA发现的最优组合
./create_best_checkpoints.sh

将创建:
- llamba_replaced_11_13_17_21  (4层, 0.5700)
- llamba_replaced_13_16_17     (3层, 0.6542)
- llamba_replaced_13_17        (2层, 0.5544)
- llamba_replaced_17           (1层, 0.5144)
- llamba_replaced_10_14_17_30  (4层备选)

预计时间: 30-50分钟
总大小: ~80GB

================================================================================
测试Checkpoint
================================================================================

cd model_preparation/

# 快速推理测试
python test_checkpoint.py \
    --checkpoint ../model_checkpoints/llamba_replaced_11_13_17_21

# 完整MMLU评估（快速版，limit=100）
python test_checkpoint.py \
    --checkpoint ../model_checkpoints/llamba_replaced_11_13_17_21 \
    --full_eval \
    --limit 100

# 完整MMLU评估（完整版）
python test_checkpoint.py \
    --checkpoint ../model_checkpoints/llamba_replaced_11_13_17_21 \
    --full_eval

================================================================================
使用Checkpoint
================================================================================

方法1: 直接加载（Python）
---------------------------
import torch
from transformers import AutoTokenizer

# 加载模型
model = torch.load('model_checkpoints/llamba_replaced_11_13_17_21/model.pt')
model.eval()
model = model.cuda()

# 加载tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    'model_checkpoints/llamba_replaced_11_13_17_21/tokenizer'
)

# 推理
inputs = tokenizer("Hello", return_tensors="pt").to('cuda')
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0]))

方法2: 查看Checkpoint信息
---------------------------
import json

with open('model_checkpoints/llamba_replaced_11_13_17_21/checkpoint_info.json') as f:
    info = json.load(f)
    print(f"Replaced layers: {info['replaced_layers']}")
    print(f"MMLU score: {info['mmlu_score']}")

================================================================================
Checkpoint目录结构
================================================================================

model_checkpoints/llamba_replaced_11_13_17_21/
├── model.pt                # 完整模型 (~16GB) ⭐ 主要使用这个
├── model_state_dict.pt     # State dict (~16GB)
├── tokenizer/              # Tokenizer文件
├── checkpoint_info.json    # 元数据（层配置、分数等）
└── README.txt              # 使用说明

================================================================================
重要提示
================================================================================

⚠️  Checkpoint文件很大（~16GB），不要提交到Git
    .gitignore已配置排除model_checkpoints/

⚠️  需要先提取Llama层文件
    运行: python extract_layers.py --model_name llama --output_dir ../extracted_llama_layers

⚠️  创建checkpoint需要GPU显存（~20GB）
    如果GPU不足，使用显存更大的GPU或关闭其他进程

✅ Checkpoint可以跨机器使用
   只需复制整个checkpoint目录即可

✅ Checkpoint包含完整模型，无需原始模型文件
   可以独立部署和使用

================================================================================
故障排除
================================================================================

Q: FileNotFoundError: Layer file not found
A: 先运行 extract_layers.py 提取Llama层

Q: CUDA out of memory
A: 使用显存更大的GPU，或指定--gpu参数使用其他GPU

Q: 加载checkpoint失败
A: 检查PyTorch版本，确保checkpoint文件完整

================================================================================
详细文档
================================================================================

📚 完整指南: MODEL_CHECKPOINTS_GUIDE.md
📚 项目主文档: README.md
📚 安装指南: SETUP.md

================================================================================

快速命令速查:

# 创建单个checkpoint
cd model_preparation && python create_replaced_model_checkpoint.py --layers 11 13 17 21 --output_dir ../model_checkpoints/best

# 批量创建
cd model_preparation && ./create_best_checkpoints.sh

# 测试
cd model_preparation && python test_checkpoint.py --checkpoint ../model_checkpoints/best --full_eval --limit 100

# 使用
python -c "import torch; model = torch.load('model_checkpoints/best/model.pt'); print('✅ Loaded!')"

================================================================================
