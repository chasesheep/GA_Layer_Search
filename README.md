# é—ä¼ ç®—æ³•å±‚æ›¿æ¢æœç´¢ç³»ç»Ÿ

> åŸºäºé—ä¼ ç®—æ³•çš„å¤§è¯­è¨€æ¨¡å‹å±‚æ›¿æ¢ä¼˜åŒ–æœç´¢ï¼Œé«˜æ•ˆæ‰¾åˆ°æœ€ä¼˜Llamaå±‚æ›¿æ¢ç»„åˆã€‚

**æ ¸å¿ƒæˆæœ**ï¼šé€šè¿‡GAæœç´¢æ‰¾åˆ°æœ€ä¼˜å±‚ç»„åˆï¼Œå¹¶ç”Ÿæˆå¯ç›´æ¥éƒ¨ç½²çš„æ¨¡å‹checkpointã€‚

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

### é—®é¢˜
å¦‚ä½•ä»Llamaæ¨¡å‹ä¸­é€‰æ‹©æœ€ä¼˜çš„å‡ å±‚ï¼Œæ›¿æ¢åˆ°Llambaæ¨¡å‹ä¸­ä»¥æå‡æ€§èƒ½ï¼Ÿ

### è§£å†³æ–¹æ¡ˆ
æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ª**ä¸‰é˜¶æ®µé—ä¼ ç®—æ³•æœç´¢æ¡†æ¶**ï¼š

```
é˜¶æ®µ1: GAç²—æœç´¢ (å¿«é€Ÿè¯„ä¼°)
   â†“
é˜¶æ®µ2: å®Œæ•´è¯„ä¼°topå€™é€‰
   â†“
é˜¶æ®µ3: å±€éƒ¨ç²¾ç»†ä¼˜åŒ–
   â†“
æœ€ä¼˜å±‚ç»„åˆ + å¯éƒ¨ç½²checkpoint
```

### æ ¸å¿ƒç‰¹æ€§

- **æ™ºèƒ½æœç´¢**ï¼šç»“åˆæ¨¡å¼æŒ–æ˜ã€å¼•å¯¼å˜å¼‚ã€ä¸¤é˜¶æ®µå±€éƒ¨æœç´¢
- **é«˜æ•ˆè¯„ä¼°**ï¼šå¿«é€Ÿè¯„ä¼°ç­›é€‰ + å®Œæ•´è¯„ä¼°éªŒè¯ï¼ŒèŠ‚çœ80%+æ—¶é—´
- **å³ç”¨checkpoint**ï¼šä¸€é”®ç”ŸæˆåŒ…å«å®Œæ•´æƒé‡çš„æ¨¡å‹checkpoint
- **è‡ªåŠ¨åŒ–éƒ¨ç½²**ï¼šä¸€é”®è„šæœ¬å®Œæˆç¯å¢ƒã€æ¨¡å‹ã€æµ‹è¯•å…¨æµç¨‹

### æœç´¢ç»“æœç¤ºä¾‹ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰

| æ’å | å±‚ç»„åˆ | MMLUåˆ†æ•° | å±‚æ•° |
|------|---------|----------|------|
| 1 | [11, 13, 17, 29] | 0.5877 | 4å±‚ |
| 2 | [9, 13, 14, 17] | 0.5751 | 4å±‚ |
| 3 | [8, 13, 14, 17] | 0.5737 | 4å±‚ |
| 4 | [12, 14, 17, 25] | 0.5649 | 4å±‚ |
| 5 | [13, 14, 17] | 0.5628 | 3å±‚ |

*æ³¨ï¼šåŸºäºå¿«é€Ÿæµ‹è¯•ç»“æœï¼ˆlimit=10/50ï¼‰ï¼Œå®Œæ•´æœç´¢ç»“æœå¯èƒ½æ›´ä¼˜*

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1ï¼šä¸€é”®éƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†é¡¹ç›®
git clone <repository> GA_Layer_Search
cd GA_Layer_Search

# è¿è¡Œè‡ªåŠ¨åŒ–éƒ¨ç½²ï¼ˆåŒ…å«ç¯å¢ƒã€æ¨¡å‹ã€æµ‹è¯•ï¼‰
./DEPLOY_TEST.sh
```

**å®Œæˆï¼** è„šæœ¬è‡ªåŠ¨å®Œæˆï¼š
- åˆ›å»ºcondaç¯å¢ƒ `ga_layer_search`
- å®‰è£…æ‰€æœ‰ä¾èµ–
- ä¸‹è½½æ¨¡å‹ï¼ˆLlamba + Llamaï¼‰
- æå–Llamaå±‚æ–‡ä»¶
- æµ‹è¯•æ‰€æœ‰åŠŸèƒ½

**æ—¶é—´**ï¼šé¦–æ¬¡çº¦30-60åˆ†é’Ÿï¼ˆä¸»è¦æ˜¯æ¨¡å‹ä¸‹è½½ï¼‰

### æ–¹å¼2ï¼šæ‰‹åŠ¨éƒ¨ç½²

```bash
# 1. åˆ›å»ºç¯å¢ƒ
conda create -n ga_layer_search python=3.10
conda activate ga_layer_search
pip install -r requirements.txt

# 2. å‡†å¤‡modelsç›®å½•ï¼ˆå¤åˆ¶æˆ–è®©è„šæœ¬è‡ªåŠ¨å¤„ç†ï¼‰
cp -r /path/to/Gather-and-Aggregate/models ./

# 3. æå–Llamaå±‚æ–‡ä»¶
cd model_preparation
python extract_layers.py --model_name llama --output_dir ../extracted_llama_layers

# 4. éªŒè¯
python test_specific_combination.py --layers 17 --gpu_id 0 --limit 10
```

---

## ğŸ“¦ ç”Ÿæˆå¯éƒ¨ç½²çš„æ¨¡å‹Checkpoint

### ä»€ä¹ˆæ˜¯Checkpointï¼Ÿ

GAæœç´¢çš„ç»“æœæ˜¯**å±‚ç´¢å¼•**ï¼ˆå¦‚`[11, 13, 17, 21]`ï¼‰ï¼Œä½†è¦å®é™…ä½¿ç”¨æ¨¡å‹ï¼Œéœ€è¦ç”ŸæˆåŒ…å«å®Œæ•´æƒé‡çš„checkpointã€‚

### ç”Ÿæˆå•ä¸ªCheckpoint

```bash
cd model_preparation/

# ç”Ÿæˆæœ€ä¼˜4å±‚ç»„åˆçš„checkpoint
python create_replaced_model_checkpoint.py \
    --layers 11 13 17 21 \
    --output_dir ../model_checkpoints/best_4layer \
    --description "GAæœç´¢æœ€ä¼˜4å±‚ç»„åˆ" \
    --score 0.5700 \
    --gpu 0
```

**è¾“å‡º**ï¼ˆ~16GBï¼‰ï¼š
- `model.pt` - å®Œæ•´æ¨¡å‹ï¼ˆå¯ç›´æ¥`torch.load()`ï¼‰
- `tokenizer/` - Tokenizeræ–‡ä»¶
- `checkpoint_info.json` - å…ƒæ•°æ®ï¼ˆå±‚é…ç½®ã€åˆ†æ•°ç­‰ï¼‰

### æ‰¹é‡ç”Ÿæˆæ‰€æœ‰æœ€ä¼˜Checkpoint

```bash
cd model_preparation/
./create_best_checkpoints.sh
```

è‡ªåŠ¨ç”Ÿæˆ5ä¸ªæœ€ä¼˜ç»„åˆçš„checkpointï¼ˆ1-4å±‚ï¼‰

### ä½¿ç”¨Checkpoint

```python
import torch
from transformers import AutoTokenizer

# åŠ è½½æ¨¡å‹
model = torch.load('model_checkpoints/best_4layer/model.pt')
model.eval().cuda()

# åŠ è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained('model_checkpoints/best_4layer/tokenizer')

# æ¨ç†
inputs = tokenizer("Hello world", return_tensors="pt").cuda()
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0]))
```

### æµ‹è¯•Checkpoint

```bash
cd model_preparation/

# å¿«é€Ÿæµ‹è¯•
python test_checkpoint.py --checkpoint ../model_checkpoints/best_4layer

# MMLUè¯„ä¼°
python test_checkpoint.py \
    --checkpoint ../model_checkpoints/best_4layer \
    --full_eval \
    --limit 100
```

---

## ğŸ”¬ è¿è¡ŒGAæœç´¢ï¼ˆå¯é€‰ï¼‰

å¦‚æœæƒ³è‡ªå·±è¿è¡Œæœç´¢æ‰¾åˆ°æ–°çš„æœ€ä¼˜ç»„åˆï¼š

### å¿«é€Ÿæµ‹è¯•ï¼ˆ~4-5å°æ—¶ï¼‰

```bash
cd scripts/
./quick_test_real.sh
```

é…ç½®ï¼šç§ç¾¤20ï¼Œä»£æ•°15ï¼Œlimit=10/50

### å®Œæ•´æœç´¢ï¼ˆ~3-5å¤©ï¼‰

```bash
cd scripts/
./run_full_search_fast.sh
```

é…ç½®ï¼šç§ç¾¤40ï¼Œä»£æ•°20ï¼Œlimit=20/None

### ç»“æœæŸ¥çœ‹

```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f results/real_*/search_log_*.txt

# æŸ¥çœ‹æœ€ç»ˆç»“æœ
cat results/real_*/search_result_*.json | python -m json.tool
```

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
GA_Layer_Search/
â”œâ”€â”€ genetic_algorithm/       # GAæœç´¢æ ¸å¿ƒä»£ç 
â”œâ”€â”€ model_preparation/       # æ¨¡å‹å‡†å¤‡å’Œcheckpointå·¥å…·
â”‚   â”œâ”€â”€ extract_layers.py   # æå–Llamaå±‚
â”‚   â”œâ”€â”€ create_replaced_model_checkpoint.py  # â­ ç”Ÿæˆcheckpoint
â”‚   â”œâ”€â”€ test_checkpoint.py  # æµ‹è¯•checkpoint
â”‚   â””â”€â”€ create_best_checkpoints.sh  # æ‰¹é‡ç”Ÿæˆ
â”œâ”€â”€ scripts/                 # è¿è¡Œè„šæœ¬
â”œâ”€â”€ config.sh               # é…ç½®æ–‡ä»¶
â”œâ”€â”€ DEPLOY_TEST.sh          # ä¸€é”®éƒ¨ç½²è„šæœ¬
â””â”€â”€ requirements.txt        # Pythonä¾èµ–

è¿è¡Œæ—¶ç”Ÿæˆï¼ˆä¸åœ¨Gitä¸­ï¼‰ï¼š
â”œâ”€â”€ extracted_llama_layers/  # Llamaå±‚æ–‡ä»¶ï¼ˆ~40GBï¼‰
â”œâ”€â”€ model_checkpoints/       # ç”Ÿæˆçš„checkpointï¼ˆ~16GB/ä¸ªï¼‰
â”œâ”€â”€ modelscope_cache/        # æ¨¡å‹ç¼“å­˜
â””â”€â”€ results/                 # æœç´¢ç»“æœ
```

---

## ğŸ’¡ æ ¸å¿ƒç®—æ³•

### ä¸‰é˜¶æ®µæœç´¢æµç¨‹

1. **é˜¶æ®µ1ï¼šGAç²—æœç´¢**
   - æ™ºèƒ½åˆå§‹åŒ–ï¼ˆç²¾è‹±ç§å­ + å¯å‘å¼ + éšæœºï¼‰
   - æ¨¡å¼æŒ–æ˜å’Œå¼•å¯¼å˜å¼‚
   - å¿«é€Ÿè¯„ä¼°ï¼ˆlimit=20-50ï¼‰æ¢ç´¢æœç´¢ç©ºé—´
   - è¾“å‡ºï¼štop-20å€™é€‰

2. **é˜¶æ®µ2ï¼šå®Œæ•´è¯„ä¼°**
   - å¯¹top-20å€™é€‰è¿›è¡Œå®Œæ•´MMLUè¯„ä¼°
   - å»é™¤å™ªéŸ³ï¼Œæ‰¾åˆ°çœŸå®top-10

3. **é˜¶æ®µ3ï¼šå±€éƒ¨ç²¾ç‚¼**
   - ä¸¤é˜¶æ®µå±€éƒ¨æœç´¢ï¼ˆç²—è¯„ä¼°ç­›é€‰ + å®Œæ•´è¯„ä¼°éªŒè¯ï¼‰
   - å¯¹top-3è¿›è¡Œé‚»åŸŸæœç´¢
   - ç¡®è®¤å±€éƒ¨æœ€ä¼˜

### æ•ˆç‡ä¼˜åŠ¿

- ä¼ ç»Ÿæ–¹æ³•ï¼š~1400æ¬¡å®Œæ•´è¯„ä¼°ï¼Œ~580å°æ—¶ï¼ˆ24å¤©ï¼‰
- **æœ¬æ–¹æ³•**ï¼š~1400æ¬¡å¿«é€Ÿè¯„ä¼° + ~50æ¬¡å®Œæ•´è¯„ä¼°ï¼Œ~150å°æ—¶ï¼ˆ6å¤©ï¼‰
- **èŠ‚çœæ—¶é—´ï¼š80%+**

---

## ğŸ› ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶
- **GPU**: 18GB+ æ˜¾å­˜ï¼ˆæ¨èRTX A6000 48GBï¼‰
- **CPU**: å¤šæ ¸CPU
- **å†…å­˜**: 32GB+ RAM
- **ç¡¬ç›˜**: 100GB+ å¯ç”¨ç©ºé—´

### è½¯ä»¶
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 18.04+)
- **Python**: 3.10
- **CUDA**: 11.x or 12.x
- **Conda**: Minicondaæˆ–Anaconda

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- **SETUP.md** - è¯¦ç»†å®‰è£…é…ç½®æŒ‡å—
- **MODEL_CHECKPOINTS_GUIDE.md** - Checkpointç”Ÿæˆå’Œä½¿ç”¨å®Œæ•´æŒ‡å—
- **CHECKPOINT_QUICKSTART.txt** - å¿«é€Ÿå‘½ä»¤å‚è€ƒ
- **DEPLOYMENT_READY.md** - éƒ¨ç½²æ£€æŸ¥æ¸…å•
- **ARCHITECTURE.md** - æŠ€æœ¯æ¶æ„ï¼ˆå¼€å‘è€…ï¼‰

---

## â“ å¸¸è§é—®é¢˜

### Q: é¦–æ¬¡éƒ¨ç½²éœ€è¦å¤šä¹…ï¼Ÿ
A: 30-60åˆ†é’Ÿï¼ˆä¸»è¦æ˜¯ä¸‹è½½æ¨¡å‹å’Œæå–å±‚æ–‡ä»¶ï¼‰ã€‚ä½¿ç”¨`./DEPLOY_TEST.sh`ä¸€é”®å®Œæˆã€‚

### Q: ç”Ÿæˆä¸€ä¸ªcheckpointéœ€è¦å¤šä¹…ï¼Ÿ
A: 5-10åˆ†é’Ÿï¼Œç”Ÿæˆçº¦16GBçš„å®Œæ•´æ¨¡å‹æ–‡ä»¶ã€‚

### Q: å¿…é¡»è¿è¡ŒGAæœç´¢å—ï¼Ÿ
A: ä¸å¿…é¡»ã€‚å¯ä»¥ç›´æ¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„æœ€ä¼˜å±‚ç»„åˆç”Ÿæˆcheckpointã€‚

### Q: å¦‚ä½•åˆ†äº«checkpointï¼Ÿ
A: Checkpointæ˜¯æ ‡å‡†çš„PyTorchæ¨¡å‹æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥å¤åˆ¶æˆ–æ‰“åŒ…åˆ†äº«ã€‚

### Q: æ”¯æŒå…¶ä»–æ¨¡å‹å—ï¼Ÿ
A: ç›®å‰é’ˆå¯¹Llamba/Llamaï¼Œä½†æ¡†æ¶å¯ä»¥è¿ç§»åˆ°å…¶ä»–æ¨¡å‹ã€‚

---

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæ‰¾ä¸åˆ°modelsç›®å½•
```bash
# è§£å†³ï¼šä»åŸé¡¹ç›®å¤åˆ¶æˆ–è®©DEPLOY_TEST.shè‡ªåŠ¨å¤„ç†
cp -r /path/to/Gather-and-Aggregate/models ./
```

### é—®é¢˜ï¼šCUDA OOM
```bash
# è§£å†³ï¼šä½¿ç”¨æ˜¾å­˜æ›´å¤§çš„GPUï¼Œæˆ–å‡å°batch_size
python xxx.py --gpu 1  # å°è¯•å…¶ä»–GPU
```

### é—®é¢˜ï¼šå±‚æ–‡ä»¶ä¸å­˜åœ¨
```bash
# è§£å†³ï¼šè¿è¡Œå±‚æå–è„šæœ¬
cd model_preparation
python extract_layers.py --model_name llama --output_dir ../extracted_llama_layers
```

---

## ğŸ“„ å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{ga_layer_search_2025,
  title={GA Layer Search: Genetic Algorithm for LLM Layer Replacement Optimization},
  author={Hu, Zhuangfei},
  year={2025},
  url={https://github.com/...}
}
```

---

## ğŸ“§ è”ç³»æ–¹å¼

- **ä½œè€…**: Zhuangfei Hu
- **é‚®ç®±**: [æ‚¨çš„é‚®ç®±]
- **é¡¹ç›®**: GA_Layer_Search
- **ç‰ˆæœ¬**: v1.0
- **æœ€åæ›´æ–°**: 2025-10-15

---

## ğŸ“ è®¸å¯è¯

MIT License

---

**ğŸ¯ æ ¸å¿ƒæµç¨‹æ€»ç»“**ï¼š

```bash
# 1. ä¸€é”®éƒ¨ç½²
./DEPLOY_TEST.sh

# 2. ç”Ÿæˆcheckpoint
cd model_preparation
python create_replaced_model_checkpoint.py --layers 11 13 17 21 --output_dir ../model_checkpoints/best

# 3. ä½¿ç”¨checkpoint
python -c "import torch; model = torch.load('model_checkpoints/best/model.pt'); print('âœ… Ready!')"
```

**å°±è¿™ä¹ˆç®€å•ï¼** ğŸš€
