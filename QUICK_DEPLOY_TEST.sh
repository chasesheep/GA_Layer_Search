#!/bin/bash
# å¿«é€Ÿéƒ¨ç½²æµ‹è¯• - éªŒè¯ç¯å¢ƒå’Œä»£ç ï¼Œä¸ä¸‹è½½å¤§æ–‡ä»¶

set -e

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "${PROJECT_ROOT}"

echo "========================================================================"
echo "å¿«é€Ÿéƒ¨ç½²æµ‹è¯•ï¼ˆä¸ä¸‹è½½å¤§æ–‡ä»¶ï¼‰"
echo "========================================================================"
echo ""

ENV_NAME="ga_layer_search"

# 1. åˆ›å»ºç¯å¢ƒ
echo "1ï¸âƒ£  åˆ›å»ºCondaç¯å¢ƒ..."
if conda env list | grep -q "^${ENV_NAME} "; then
    echo "   âš ï¸  ç¯å¢ƒå·²å­˜åœ¨ï¼Œåˆ é™¤å¹¶é‡å»º..."
    conda env remove -n ${ENV_NAME} -y
fi

conda create -n ${ENV_NAME} python=3.10 -y
echo "   âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ"
echo ""

# 2. è·å–ç¯å¢ƒè·¯å¾„
ENV_PATH=$(conda env list | grep "^${ENV_NAME} " | awk '{print $NF}')
ENV_PYTHON="${ENV_PATH}/bin/python"
ENV_PIP="${ENV_PATH}/bin/pip"

echo "2ï¸âƒ£  å®‰è£…ä¾èµ–..."
echo "   ç¯å¢ƒ: ${ENV_PATH}"
echo "   å…ˆè£…numpyå’Œscipyï¼ˆé¿å…å…¼å®¹æ€§é—®é¢˜ï¼‰..."
${ENV_PIP} install -q numpy==1.26.4 scipy==1.14.1
echo "   å®‰è£…å…¶ä»–ä¾èµ–..."
${ENV_PIP} install -q -r requirements.txt
echo "   âœ… ä¾èµ–å®‰è£…å®Œæˆ"
echo ""

# 3. éªŒè¯å®‰è£…
echo "3ï¸âƒ£  éªŒè¯å®‰è£…..."
${ENV_PYTHON} -c "import torch; print(f'   âœ… PyTorch {torch.__version__}')"
${ENV_PYTHON} -c "import transformers; print(f'   âœ… Transformers {transformers.__version__}')"
${ENV_PYTHON} -c "import modelscope; print(f'   âœ… ModelScope {modelscope.__version__}')"
echo ""

# 4. æµ‹è¯•ä»£ç å¯¼å…¥
echo "4ï¸âƒ£  æµ‹è¯•ä»£ç å¯¼å…¥..."
cd genetic_algorithm
${ENV_PYTHON} -c "from config import GAConfig; from population import Population; from ga_core import GeneticAlgorithm; print('   âœ… GAæ¨¡å—å¯å¯¼å…¥')"
cd ../model_preparation
${ENV_PYTHON} -c "from modelscope_utils import get_model_modelscope; print('   âœ… æ¨¡å‹å·¥å…·å¯å¯¼å…¥')"
cd ..
echo ""

# 5. æ£€æŸ¥modelsç›®å½•
echo "5ï¸âƒ£  æ£€æŸ¥modelsç›®å½•..."
if [ -f "models/llamba.py" ]; then
    ${ENV_PYTHON} -c "import sys; sys.path.insert(0, '.'); from models.llamba import LlambaLMHeadModel; print('   âœ… models.llambaå¯å¯¼å…¥')"
else
    echo "   âŒ models/llamba.pyä¸å­˜åœ¨"
    exit 1
fi
echo ""

echo "========================================================================"
echo "âœ… å¿«é€Ÿéƒ¨ç½²æµ‹è¯•é€šè¿‡ï¼"
echo "========================================================================"
echo ""
echo "ğŸ“‹ æµ‹è¯•ç»“æœ:"
echo "   [âˆš] Condaç¯å¢ƒåˆ›å»º"
echo "   [âˆš] Pythonä¾èµ–å®‰è£…"
echo "   [âˆš] ä»£ç æ¨¡å—å¯¼å…¥"
echo "   [âˆš] modelsç›®å½•æ­£ç¡®"
echo ""
echo "ğŸ¯ ç¯å¢ƒå·²å°±ç»ªï¼Œå¯ä»¥:"
echo "   1. æå–Llamaå±‚ï¼ˆéœ€GPUï¼Œ~10åˆ†é’Ÿï¼‰:"
echo "      cd model_preparation"
echo "      ${ENV_PYTHON} extract_layers.py --model_name llama --output_dir ../extracted_llama_layers"
echo ""
echo "   2. ç”Ÿæˆcheckpointï¼ˆéœ€GPU + å±‚æ–‡ä»¶ï¼Œ~5åˆ†é’Ÿï¼‰:"
echo "      ${ENV_PYTHON} create_replaced_model_checkpoint.py --layers 11 13 17 29 --output_dir ../model_checkpoints/best"
echo ""
echo "   3. è¿è¡Œæœç´¢ï¼ˆéœ€GPU + å±‚æ–‡ä»¶ï¼Œ~æ•°å°æ—¶åˆ°æ•°å¤©ï¼‰:"
echo "      cd ../scripts && ./quick_test_real.sh"
echo ""

